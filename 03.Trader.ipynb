{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "#  <strong>알고리즘 트레이딩 시스템의 구현</strong> \n",
    "\n",
    "<strong>알고리즘 트레이딩 시스템 블록</strong>\n",
    "1. <strong>알파모델</strong> : 주가 예측\n",
    "2. <strong>리스크모델(Risk Model)</strong> : 알파모델 예측이 틀릴경우 손실을 계산\n",
    "3. <strong>거래비용모델(Transaction Cost Model)</strong> : 거래비용을 계산\n",
    "4. <strong>포트폴리오모델(Portfolio Model)</strong> : 알파/리스크/거래비용 모델을 종합하여 거래를 최종판단\n",
    "5. <strong>실행모델(Executaion Model)</strong> : 포트폴리오 결정에 따라 실제로 거래를 실행\n",
    "\n",
    "<img src=\"https://doi.ieeecomputersociety.org/cms/Computer.org/dl/mags/co/2011/11/figures/mco2011110061a.gif\" width=\"400\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<br>\n",
    "## <strong>1 구현 시스템 개요\n",
    "1. 평균회귀, 머신러닝 등을 활용하여 알파 모델을 생성생성한다\n",
    "2. 알파모델을 테스트 튜닝 뒤 실전에 적용하면 ,시간에 따라 점차 수익성이 낮아진다\n",
    "3. 이러한 Life Cycle을 '시간가치 감소효과'라고 한다\n",
    "    1. 컴퓨터 트레이딩의 범람으로, 다른 모델에 의해 나의 모델이 희석된다\n",
    "    2. 주가가 '표류하는 랜덤워크'를 따르므로, 시가니 지날수록 변동성이 커진다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sytem Block\n",
    "1. 데이터크롤러 (Data Crawler)\n",
    "1. 데이터베이스 (MySQL, PostgreSQL)\n",
    "1. 평균회귀모델/ 머신러닝모델\n",
    "1. alpha 모델\n",
    "1. Portfolio Builder\n",
    "1. Trader \n",
    "1. Back Tester : 과거데이터를 적용하여 예측 적중률을 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<br>\n",
    "## <strong>2 Data Crawler\n",
    "<strong>데이터 크롤러</strong> : Yahoo Finance/ Google Finance -> PostgreSQL 에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas_datareader import get_data_google, get_data_yahoo\n",
    "# get_data_yahoo('005930.ks','2017-01-01','2017-11-01')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<br>\n",
    "## <strong>3 alpha 모델의 구현\n",
    "1. 모델의 적합도 판단 \n",
    "2. 포지션 결정 : 매수(Long Position), 매도(Short Position)을 결정한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### <strong>01 평균회귀 모델의 구현\n",
    "모델의 랜덤워크, 회귀모델 판단"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#class AlphaModel():\n",
    "# def __init__(self):\n",
    "#     self.dbhandler = services.get('dbhandler')\n",
    "#     self.dbreader = services.get('dbreader')\n",
    "#     self.predictor = services.get('predictor')\n",
    "#     self.config = services.get('configurator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 평균회귀 적합도 판단모델\n",
    "#class MeanReversionModel(AlphaModel):\n",
    "def calcADF(self, df):\n",
    "    adf_result = ts.adfuller(df)\n",
    "    ciritical_values = adf_result[4]\n",
    "    #print ciritical_values\n",
    "    return adf_result[0], ciritical_values['1%'],ciritical_values['5%'], ciritical_values['10%']\n",
    "\n",
    "def calcHurstExponent(self,df,lags_count=100):\n",
    "    lags = range(2, lags_count)\n",
    "    ts = np.log(df)\n",
    "    tau = [np.sqrt(np.std(np.subtract(ts[lag:], ts[:-lag]))) for lag in lags]\n",
    "    poly = np.polyfit(np.log(lags), np.log(tau), 1)\n",
    "    result = poly[0]*2.0\n",
    "    return result\n",
    "\n",
    "def calcHalfLife(self,df):\n",
    "    price = pd.Series(df)  \n",
    "    lagged_price = price.shift(1).fillna(method=\"bfill\")  \n",
    "    delta = price - lagged_price  \n",
    "    beta = np.polyfit(lagged_price, delta, 1)[0] \n",
    "    half_life = (-1*np.log(2)/beta) \n",
    "    return half_life\n",
    "\n",
    "# 이동평균과 이동평균 표준편차값을 이용하여, 매도/매수 포지션을 결정한다\n",
    "# self.threshold : 이동평균과 현재주가의 차이가, 이동평균의 표준편차 보아 크고/ 작음을 판단\n",
    "def determinePosition(self,df,column,row_index,verbose=False):\n",
    "    current_price = df.loc[row_index,column]\n",
    "    df_moving_average = pd.rolling_mean(df.loc[0:row_index,column],window=self.window_size)\n",
    "    df_moving_average_std = pd.rolling_std(df.loc[0:row_index,column],window=self.window_size)\n",
    "    #print (df.loc[0:row_index,column], moving_average, df_moving_average_std)\n",
    "    moving_average = df_moving_average[row_index]\n",
    "    moving_average_std = df_moving_average_std[row_index]\n",
    "    price_arbitrage = current_price - moving_average\n",
    "#     if verbose: \n",
    "#         print(\"diff={}, price={}, moving_average={}, moving_average_std={}\".format(\n",
    "#             price_arbitrage, current_price, moving_average, moving_average_std)\n",
    "#     if abs(price_arbitrage) > moving_average_std * self.threshold:\n",
    "#         if np.sign(price_arbitrage)>0:\n",
    "#             return SHORT\n",
    "#         else:\n",
    "#             return LONG\n",
    "#     return HOLD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### <strong>02 머신러닝 모델의 구현\n",
    "앞장의 머신러닝 모델을 통해 구현한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#class MachineLearningModel(AlphaModel):\n",
    "def calcScore(self,split_ratio=0.75,time_lags=10):\n",
    "    return self.predictor.trainAll(split_ratio=split_ratio,time_lags=time_lags )\n",
    "\n",
    "# Voting 기법을 사용하여 매수/매도를 판단 : 3가지 예측모델의 판단 결과를 투표로 최종결정한다\n",
    "def determinePosition(self,code,df,column,row_index,verbose=False):\n",
    "    if (row_index-1) < 0:\n",
    "        return HOLD\n",
    "    current_price = df.loc[row_index-1,column]\n",
    "    prediction_result = 0\n",
    "    for a_predictor in ['logistic','rf','svm']:\n",
    "        predictor = self.predictor.get(code,a_predictor)\n",
    "        pred,pred_prob = predictor.predict([current_price])\n",
    "        #print(\"predictor=%s, price=%s, pred=%s, pred_proba=%s\" % (a_predictor,current_price,pred[0],pred_prob[0]))\n",
    "        prediction_result += pred[0]\n",
    "        #print (prediction_result[a_predictor])\n",
    "    #print(\"price=%s, pred_result=%s\" % (current_price,prediction_result))\n",
    "    if prediction_result>1:\n",
    "        return LONG\n",
    "    else:\n",
    "        return SHORT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<br>\n",
    "## <strong>4 포트폴리오 빌더 구현\n",
    "모델구현과 함께, 이에 적합한 종목을 골라내는 것 또한 중요한 과제이다\n",
    "1. 종목별 모델의 적합성 평가\n",
    "1. 적합성 평가 결과 순위를 지정\n",
    "1. 정해진 순위로 상위 % 종목을 추출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### <strong>01 평균회귀 모델의 종목선정\n",
    "ADF, 허스트지수, Half-Life 계수를 통해서 판단이 가능하다\n",
    "\n",
    "종목별 위의 3가지 판단을 계산하고, 그 결과를 DataFrame으로 출력한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#class PortfolioBuilder():\n",
    "# def __init__(self):\n",
    "#     self.dbhandler = services.get('dbhandler')\n",
    "#     self.dbreader = services.get('dbreader')\n",
    "#     self.predictor = services.get('predictor')\n",
    "#     self.config = services.get('configurator')\n",
    "#     self.mean_reversion_model = services.get('mean_reversion_model')\n",
    "#     self.machine_learning_model = services.get('machine_learning_model')\n",
    "\n",
    "def loadDataFrame(self,code): # SQL에서 데이터 추출\n",
    "    sql = \"select * from prices\"\n",
    "    sql += \" where code='%s'\" % (code)\n",
    "    sql += \" and price_date between '%s' and '%s' \" % (self.config.get('start_date'),self.config.get('end_date'))\n",
    "    df = pd.read_sql(sql,self.dbhandler.conn)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def assessADF(self,test_stat,adf_1,adf_5,adf_10):\n",
    "    if test_stat<adf_10:  return 3\n",
    "    elif test_stat<adf_5: return 2\n",
    "    elif test_stat<adf_1: return 1\n",
    "    return 0\n",
    "\n",
    "def assessHurst(self,hurst):\n",
    "    if hurst>0.4:   return 0\n",
    "    if hurst<0.1:   return 3\n",
    "    elif hurst<0.2: return 2\n",
    "    return 1\n",
    "\n",
    "def assessHalflife(self,percentile,halflife):\n",
    "    for index in range(len(percentile)):\n",
    "        if halflife<=percentile[index]:\n",
    "            if index<2:   return 3\n",
    "            elif index<3: return 2\n",
    "            elif index<4: return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def doStationarityTest(self,column,lags_count=100):\n",
    "    rows_code = self.dbreader.loadCodes(limit = self.config.get('data_limit'))\n",
    "    test_result = {'code':[], 'company':[], 'adf_statistic':[], \n",
    "                   'adf_1':[],'adf_5':[],'adf_10':[], 'hurst':[],'halflife':[]}\n",
    "    index = 1\n",
    "    for a_row_code in rows_code:\n",
    "        code = a_row_code[0]\n",
    "        company = a_row_code[1]\n",
    "        print(\"... %s of %s : Testing Stationarity on %s %s\" % (index,len(rows_code),code,company))\n",
    "        a_df = self.loadDataFrame(code)\n",
    "        a_df_column = a_df[column]\n",
    "        if a_df_column.shape[0]>0:\n",
    "            test_result['code'].append(code)\n",
    "            test_result['company'].append(company)\n",
    "            test_result['hurst'].append(self.mean_reversion_model.calcHurstExponent(a_df_column,lags_count))\n",
    "            test_result['halflife'].append(self.mean_reversion_model.calcHalfLife(a_df_column))\n",
    "            test_stat, adf_1,adf_5,adf_10 = self.mean_reversion_model.calcADF(a_df_column)\n",
    "            test_result['adf_statistic'].append(test_stat)\n",
    "            test_result['adf_1'].append(adf_1)\n",
    "            test_result['adf_5'].append(adf_5)\n",
    "            test_result['adf_10'].append(adf_10)\n",
    "        index += 1\n",
    "    df_result = pd.DataFrame(test_result)\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 계산된 결과에 따른 종목별 적합도 순위 결정\n",
    "def rankStationarity(self,df_stationarity):\n",
    "    df_stationarity['rank_adf'] = 0\n",
    "    df_stationarity['rank_hurst'] = 0\n",
    "    df_stationarity['rank_halflife'] = 0\n",
    "    halflife_percentile = np.percentile(\n",
    "        df_stationarity['halflife'], np.arange(0, 100, 10)) # quartiles\n",
    "    for row_index in range(df_stationarity.shape[0]):\n",
    "        df_stationarity.loc[row_index,'rank_adf'] =\\\n",
    "            self.assessADF(df_stationarity.loc[row_index,'adf_statistic'],\n",
    "                           df_stationarity.loc[row_index,'adf_1'],\n",
    "                           df_stationarity.loc[row_index,'adf_5'],\n",
    "                           df_stationarity.loc[row_index,'adf_10'])\n",
    "        df_stationarity.loc[row_index,'rank_hurst'] =\\\n",
    "            self.assessHurst(df_stationarity.loc[row_index,'hurst'])\n",
    "        df_stationarity.loc[row_index,'rank_halflife'] =\\\n",
    "            self.assessHalflife(halflife_percentile, \n",
    "                                df_stationarity.loc[row_index,'halflife'])\n",
    "    df_stationarity['rank'] = df_stationarity['rank_adf'] +\\\n",
    "                              df_stationarity['rank_hurst'] +\\\n",
    "                              df_stationarity['rank_halflife']\n",
    "    return df_stationarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 순위결과에 따른 종목선정 : ratio (선정비율)\n",
    "def buildUniverse(self, df_stationarity, column,  ratio):\n",
    "    percentile_column = np.percentile(df_stationarity[column], np.arange(0, 100, 10))\n",
    "    ratio_index = np.trunc(ratio * len(percentile_column))\n",
    "    universe = {}\n",
    "    for row_index in range(df_stationarity.shape[0]):\t\t\n",
    "        percentile_index = getPercentileIndex(\n",
    "            percentile_column, df_stationarity.loc[row_index,column])\n",
    "        if percentile_index >= ratio_index:\n",
    "            universe[df_stationarity.loc[row_index,'code']] =\\\n",
    "                        df_stationarity.loc[row_index,'company']\n",
    "    return universe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### <strong>02 머신러닝 모델의 종목선정\n",
    "앞장의 머신러닝 모델을 통해 구현한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def doMachineLearningTest(self,split_ratio=0.75,lags_count=10):\n",
    "    return self.machine_learning_model.calcScore(\n",
    "            split_ratio = split_ratio, time_lags = lags_count )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def assessMachineLearning(self,percentile,halflife):\n",
    "    for index in range(len(percentile)):\n",
    "        if halflife<=percentile[index]:\n",
    "            if index<2:   return 3\n",
    "            elif index<3: return 2\n",
    "            elif index<4: return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### <strong>03 평균회귀 모델의 종목선정\n",
    "ADF, 허스트지수, Half-Life 계수를 통해서 판단이 가능하다\n",
    "\n",
    "종목별 위의 3가지 판단을 계산하고, 그 결과를 DataFrame으로 출력한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rankMachineLearning(self,df_machine_learning):\n",
    "    def listed_columns(arr,prefix):\n",
    "        result = []\n",
    "        for a_item in arr:\n",
    "            result.append( prefix % (a_item) )\n",
    "        return result\n",
    "    mr_models = ['logistic','rf','svm']\n",
    "    for a_predictor in mr_models:\n",
    "        df_machine_learning['rank_%s' % (a_predictor)] = 0\n",
    "    percentiles = {}\n",
    "    for a_predictor in mr_models:\n",
    "        percentiles[a_predictor] = np.percentile(df_machine_learning[a_predictor], np.arange(0, 100, 10))\n",
    "        for row_index in range(df_machine_learning.shape[0]):\n",
    "            df_machine_learning.loc[row_index,'rank_%s' % (a_predictor)] =\\\n",
    "                    self.assessMachineLearning(percentiles[a_predictor],\n",
    "                                               df_machine_learning.loc[row_index,a_predictor])\n",
    "    df_machine_learning['total_score'] = df_machine_learning[mr_models].sum(axis=1)\n",
    "    df_machine_learning['rank'] = df_machine_learning[ listed_columns(mr_models,'rank_%s') ].sum(axis=1)\n",
    "    return df_machine_learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<br>\n",
    "## <strong>5 트레이더 구현\n",
    "PortFolio 클래스에 담긴 종목들을 가상으로 적용해서 매수/ 매도 포지션을 기록한다"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
